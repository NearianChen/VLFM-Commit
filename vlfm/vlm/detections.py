# Copyright (c) 2023 Boston Dynamics AI Institute LLC. All rights reserved.

from typing import List, Optional, Tuple

import cv2
import numpy as np
import torch

try:
    from torchvision.ops import box_convert
except ImportError:
    print("Could not import box_convert. This is OK if you are only using the client.")


class ObjectDetections:
    """
    Provides a consistent format for object detections generated by both object
    detection and grounding models.
    
    为对象检测和视觉定位模型生成的检测结果提供统一格式。
    """

    def __init__(
        self,
        boxes: torch.Tensor,  # 边界框坐标的张量
        logits: torch.Tensor,  # 置信度分数的张量
        phrases: List[str],    # 类别名称列表
        image_source: Optional[np.ndarray],  # 源图像数据
        fmt: str = "cxcywh",   # 边界框格式，默认为中心点+宽高格式
    ):
        """
        初始化对象检测结果类
        
        Args:
            boxes: 边界框坐标张量
            logits: 检测置信度分数张量
            phrases: 检测到的对象类别名称列表
            image_source: 原始图像数据
            fmt: 输入边界框的格式，默认为"cxcywh"(中心点x,y和宽高)
        """
        self.image_source = image_source
        if fmt != "xyxy":
            # 如果输入格式不是xyxy，则转换为xyxy格式(左上和右下角坐标)
            self.boxes = box_convert(boxes=boxes, in_fmt=fmt, out_fmt="xyxy")
        else:
            self.boxes = boxes
        self.logits = logits
        self.phrases = phrases
        self._annotated_frame: Optional[np.ndarray] = None  # 标注后的图像，初始为None

    @property
    def annotated_frame(self) -> Optional[np.ndarray]:
        """
        获取标注了检测结果的图像
        如果尚未创建标注图像且有源图像，则进行标注
        
        Returns:
            标注了边界框和类别的图像，如果没有源图像则返回None
        """
        if self._annotated_frame is None and self.image_source is not None:
            self._annotated_frame = annotate(
                image_source=self.image_source,
                boxes=self.boxes,
                logits=self.logits,
                phrases=self.phrases,
            )
        return self._annotated_frame

    @property
    def num_detections(self) -> int:
        """
        返回检测到的对象数量。
        
        Returns:
            检测结果的数量
        """
        return len(self.phrases)

    def __repr__(self) -> str:
        """
        输出每个检测结果的类别、分数和边界框
        用于打印对象时的字符串表示
        
        Returns:
            包含所有检测结果信息的字符串
        """
        dets = [
            f"{phrase} ({logit:.2f}): {box.tolist()}"
            for box, logit, phrase in zip(self.boxes, self.logits, self.phrases)
        ]
        if len(dets) == 0:
            return "No detections"  # 没有检测结果
        return "\n".join(dets)

    def filter_by_conf(self, conf_thresh: float) -> None:
        """
        基于置信度阈值进行原地过滤检测结果。
        
        Args:
            conf_thresh (float): 过滤检测结果的置信度阈值。
        """
        keep: torch.Tensor = torch.ge(self.logits, conf_thresh)  # 保留大于等于阈值的结果
        self._filter(keep)

    def filter_by_class(self, classes: List[str]) -> None:
        """
        基于类别名称进行原地过滤检测结果。
        
        Args:
            classes (List[str]): 要保留的类别列表。
        """
        keep: torch.Tensor = torch.tensor([p in classes for p in self.phrases], dtype=torch.bool)
        self._filter(keep)

    def _filter(self, keep: torch.Tensor) -> None:
        """
        根据布尔掩码原地过滤检测结果。
        
        Args:
            keep: 布尔张量，表示哪些检测结果应该保留
        """
        # 如果所有结果都保留，则提前返回
        if keep.all():
            return

        # 根据掩码过滤边界框、分数和类别名称
        self.boxes = self.boxes[keep]
        self.logits = self.logits[keep]
        self.phrases = [p for i, p in enumerate(self.phrases) if keep[i]]
        self._annotated_frame = None  # 重置标注图像，需要重新生成

    def to_json(self) -> dict:
        """
        将对象检测结果转换为可JSON序列化的格式。
        
        Returns:
            dict: 包含检测结果的字典。
        """
        return {
            "boxes": self.boxes.tolist(),  # 将张量转换为列表
            "logits": self.logits.tolist(),
            "phrases": self.phrases,
        }

    @classmethod
    def from_json(
        cls,
        json_dict: dict,  # JSON格式的检测结果
        image_source: Optional[np.ndarray] = None,  # 可选的源图像
    ) -> "ObjectDetections":
        """
        从JSON可序列化格式转换回对象检测结果。
        
        Args:
            json_dict (dict): 包含检测结果的字典。
            image_source (Optional[np.ndarray], optional): 可选提供原始图像。默认为None。
            
        Returns:
            ObjectDetections: 检测结果对象
        """
        return cls(
            image_source=image_source,
            boxes=torch.tensor(json_dict["boxes"]),  # 将列表转换回张量
            logits=torch.tensor(json_dict["logits"]),
            phrases=json_dict["phrases"],
            fmt="xyxy",  # JSON中的格式始终为xyxy
        )


def annotate(
    image_source: np.ndarray,  # 源图像
    boxes: torch.Tensor,       # 边界框坐标
    logits: torch.Tensor,      # 置信度分数
    phrases: List[str],        # 类别名称
) -> np.ndarray:
    """
    用边界框、类别名称和分数标注图像。
    
    Args:
        image_source (np.ndarray): numpy数组格式的输入图像。
        boxes (torch.Tensor): 形状为(N, 4)的张量，包含图像中每个对象的边界框。
            边界框应采用(x1, y1, x2, y2)格式。
        logits (torch.Tensor): 形状为(N, C)的张量，包含图像中每个对象的置信度分数。
        phrases (List[str]): 包含图像中每个对象的类别名称的字符串列表。

    Returns:
        np.ndarray: 带有边界框、类别名称和分数标注的原始图像。
    """
    img = image_source.copy()  # 复制图像以避免修改原始图像

    # 在图像上绘制边界框、类别名称和分数
    for box, prob, phrase in zip(boxes, logits, phrases):
        # 将张量转换为numpy数组
        box = box.detach().cpu().numpy()
        prob = prob.detach().cpu().numpy()

        # 如果边界框坐标似乎是归一化的(0-1)，则使用图像尺寸反归一化
        if box.max() <= 1:
            box = box * np.array([img.shape[1], img.shape[0], img.shape[1], img.shape[0]])
            box = box.astype(int)

        # 绘制边界框
        point1 = (int(box[0]), int(box[1]))  # 左上角坐标
        point2 = (int(box[2]), int(box[3]))  # 右下角坐标
        img = draw_bounding_box(
            image=img,
            point1=point1,
            point2=point2,
            class_name=phrase,
            score=prob.max(),
        )

    return img


def draw_bounding_box(
    image: np.ndarray,  # 输入图像
    point1: Tuple[int, int],  # 边界框左上角坐标
    point2: Tuple[int, int],  # 边界框右下角坐标
    class_name: str,    # 类别名称
    score: float,       # 置信度分数
    color: Optional[Tuple[int, int, int]] = None,  # 边界框颜色
) -> np.ndarray:
    """
    在图像上绘制边界框并标注类别名称和分数。
    
    Args:
        image (np.ndarray): RGB格式的numpy数组输入图像。
        point1 (Tuple[int, int]): 边界框左上角的坐标。
        point2 (Tuple[int, int]): 边界框右下角的坐标。
        class_name (str): 表示边界框内预测对象的类别名称的字符串。
        score (float): 边界框内预测对象的置信度分数。应在0.0到1.0范围内。
        color (Optional[Tuple[int, int, int]]): 包含边界框颜色的RGB值(0-255)的元组。
            如果为None，则随机选择颜色。

    Returns:
        np.ndarray: 带有边界框和相应类别名称及分数标注的原始图像。
    """
    # 创建输入图像的副本用于绘制，并转换为BGR格式(OpenCV格式)
    img = cv2.cvtColor(image.copy(), cv2.COLOR_RGB2BGR)

    if color is None:
        # 从彩虹色图中随机选择一种颜色(避免边界框为黑色)
        single_pixel = np.array([[np.random.randint(0, 256)]], dtype=np.uint8)
        single_pixel = cv2.applyColorMap(single_pixel, cv2.COLORMAP_RAINBOW)

        # 将颜色数组重塑为一维数组
        rand_color = single_pixel.reshape(3)
        bgr_color = [int(c) for c in rand_color]  # type: ignore
    else:
        # 将RGB转换为BGR(OpenCV使用BGR格式)
        color = color[::-1]
        bgr_color = [int(c) for c in color]

    # 在图像上绘制边界框
    box_thickness = 2  # 边界框线条粗细
    cv2.rectangle(img, point1, point2, bgr_color, thickness=box_thickness)

    # 在图像上绘制类别名称和分数
    text_label = f"{class_name}: {int(score * 100)}%"  # 格式化标签文本
    font = cv2.FONT_HERSHEY_SIMPLEX  # 使用的字体
    font_scale = 0.5  # 字体大小
    font_thickness = 1  # 字体粗细
    text_size, _ = cv2.getTextSize(text_label, font, font_scale, font_thickness)  # 获取文本尺寸
    text_x = point1[0]  # 文本x坐标
    text_y = point2[1] + text_size[1]  # 文本y坐标
    # 绘制文本背景矩形
    cv2.rectangle(
        img,
        (text_x, text_y - 2 * text_size[1]),
        (text_x + text_size[0], text_y - text_size[1]),
        bgr_color,
        -1,  # -1表示填充矩形
    )
    # 绘制文本
    cv2.putText(
        img,
        text_label,
        (text_x, text_y - text_size[1] - box_thickness),
        font,
        font_scale,
        (0, 0, 0),  # 黑色文本
        font_thickness,
    )

    # 将图像从BGR转回RGB格式
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    return img
